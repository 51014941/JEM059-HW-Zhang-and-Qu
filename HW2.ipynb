{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9194b51e",
   "metadata": {},
   "source": [
    "# Financial Econometrics I: Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a232b2",
   "metadata": {},
   "source": [
    "Team Member:\n",
    "\n",
    "Lin Zhang : 15845542@fsv.cuni.cz\n",
    "\n",
    "Weiwei Qu : 51014941@fsv.cuni.cz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a2575",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c79d1",
   "metadata": {},
   "source": [
    "### Select 100 random symbols from the symbols.csv file, i.e. using a function in R generate 100 random integers from interval f1,..., 377g, use set.seed('your SIS number') to generate these numbers(e.g. set.seed(26830192)). Then select the Tickers from rows with indices equal to the numbers you generated, and download the prices of stocks denoted by these Tickers for the period 01/2019 - 12/2021. Please restrict the period immediately when downloading the data, it should get downloaded more quickly then."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa4d38",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc66a81",
   "metadata": {},
   "source": [
    "* Setup environment and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "Sys.setenv(LANG = \"en\")\n",
    "Sys.setlocale(\"LC_TIME\", \"English\")\n",
    "#options(warn = -1)  # suppressing warnings\n",
    "\n",
    "if (!require(quantmod)) install.packages('quantmod')\n",
    "if (!require(fGarch)) install.packages('fGarch')\n",
    "if (!require(repr)) install.packages('repr')\n",
    "if (!require(rugarch)) install.packages('rugarch')\n",
    "if (!require(aTSA)) install.packages('aTSA')\n",
    "if (!require(tseries)) install.packages('tseries')\n",
    "if (!require(fDMA)) install.packages('fDMA')\n",
    "if (!require(ggplot2)) install.packages('ggplot2')\n",
    "if (!require(ggthemes)) install.packages('ggthemes')\n",
    "\n",
    "\n",
    "library(quantmod)\n",
    "library(fGarch)\n",
    "library(repr)\n",
    "library(forecast)\n",
    "library(aTSA)\n",
    "library(rugarch)\n",
    "library(tseries)\n",
    "library(fDMA)\n",
    "library(ggplot2)\n",
    "library(ggthemes) \n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ec356",
   "metadata": {},
   "source": [
    "* Select 100 random symbols from requirement file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 377 stock symbols from file\n",
    "smbs<- as.character(read.csv(\"symbols2.csv\")[,2])\n",
    "length(smbs)\n",
    "smbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea3a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(15845542) # seed for random number generation\n",
    "s_symbols<-sample(smbs,100) # generate 100 random firms\n",
    "length(s_symbols)\n",
    "s_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d006d64",
   "metadata": {},
   "source": [
    "* Download closing price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63188459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "stock_price <- lapply(s_symbols, function(y)\n",
    "{\n",
    "    getSymbols(y, auto.assign = FALSE,from = as.Date('2019-01-01'), to = '2021-12-31')\n",
    "})\n",
    "names(stock_price) <- s_symbols\n",
    "\n",
    "# save data for further usage\n",
    "#  save(stock_price, file = \"1-Price.RData\")\n",
    "# load(\"1-Price.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b0e3c",
   "metadata": {},
   "source": [
    "* Check the data validityï¼ˆReference the Hw1 solution from SIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "par(bg = \"#f7f7f7\")\n",
    "stock_price1 <- sapply(stock_price,na.omit)\n",
    "nrows <- unlist(sapply(stock_price1, nrow))\n",
    "plot(nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ae17e",
   "metadata": {},
   "source": [
    "Clearly there is one stock does not have enough data set from downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "length(stock_price1[[1]])\n",
    "length(stock_price1[[43]])\n",
    "tail(stock_price1[[43]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78243ea5",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>We notied that NFX does not have enough data, it need to be removed from our portfolio.</span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8bd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price$NFX <- NULL\n",
    "length(stock_price)\n",
    "s_symbols <- names(stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c40b1",
   "metadata": {},
   "source": [
    "* Clean the data set, only need Adjusted closing price for our calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for Adjusted price\n",
    "stock_close <- lapply(s_symbols, function(y){\n",
    "    stock_price[[y]] <- stock_price[[y]][, paste0(y, '.Adjusted')]\n",
    "})\n",
    "\n",
    "# check all symbols used for downloading process are used, no data is missing\n",
    "length(stock_price)\n",
    "head(stock_close[[1]])\n",
    "tail(stock_close[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f60f84",
   "metadata": {},
   "source": [
    "###  1. Compute the logarithmic returns for the time-series of each stock in your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute log-returns for returns\n",
    "# multiple 100 to make easier observation\n",
    "\n",
    "lrets <- lapply(stock_close, function(y){\n",
    "  y <- na.omit(diff(log(y))) * 100\n",
    "})\n",
    "names(lrets) <- s_symbols\n",
    "\n",
    "head(lrets[[1]])\n",
    "tail(lrets[[1]])\n",
    "\n",
    "# Save data for later usage\n",
    "#  save(lrets, file = \"2-Returns.RData\")\n",
    "# load(\"2-Returns.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6c37e",
   "metadata": {},
   "source": [
    "**Note: We use <span style='background:yellow'>percentage number as returns</span>, which already be multipled by 100.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cf364",
   "metadata": {},
   "source": [
    "###  2. For each stocks, estimate the parameters of a GARCH(1, 1) model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d28bdc",
   "metadata": {},
   "source": [
    "* Apply GARCH model to estimate each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3153fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for GARCH(1,1) by ugarchspec()\n",
    "GarchSet1 <- ugarchspec(mean.model = list(armaOrder = c(0, 0)),\n",
    "                variance.model = list(garchOrder = c(1, 1)))\n",
    "\n",
    "# Create matrix stock_coef to store estimate parameters of stocks\n",
    "N <- length(lrets)  \n",
    "x <- c(1:N * 4)\n",
    "rown <- s_symbols\n",
    "coln <- c(\"alpha1\", \"beta1\", \"alpha1+beta1\", \"omega\")\n",
    "stock_coef <- matrix(x, nrow = N, ncol = 4, byrow = TRUE, \n",
    "            dimnames = list(rown, coln))\n",
    "l_alpha <- list()\n",
    "l_beta <- list()\n",
    "l_omega <- list()\n",
    "\n",
    "# Run ugarchfit() model to all stocks\n",
    "for (i in 1 : N){\n",
    "    GarchFit1 <- ugarchfit(GarchSet1, lrets[[i]])\n",
    "    l_alpha <- c(l_alpha, GarchFit1@fit$coef['alpha1'])\n",
    "    l_beta <- c(l_beta, GarchFit1@fit$coef['beta1'])  \n",
    "    l_omega <- c(l_omega, GarchFit1@fit$coef['omega'])  \n",
    "}\n",
    "\n",
    "for (i in 1 : N){\n",
    "    stock_coef[i,1] <- round(l_alpha[[i]],6)\n",
    "    stock_coef[i,2] <- round(l_beta[[i]],6)    \n",
    "    stock_coef[i,4] <- round(l_omega[[i]],6) \n",
    "}\n",
    "stock_coef[,3] <- stock_coef[,1] + stock_coef[,2]\n",
    "\n",
    "head(stock_coef)\n",
    "tail(stock_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281bfbc",
   "metadata": {},
   "source": [
    "**We store those coefficient parameters of all stocks into a matrix named <span style='background:yellow'>\"stock_coef\"</span>.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for later usage\n",
    "#  save(stock_coef, file = \"3-Coef.RData\")\n",
    "# load(\"3-Coef.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc3b0b",
   "metadata": {},
   "source": [
    "### 3. You will end up with 100 sets of estimated coefficients. Plot the histogram of the 100 $\\alpha_1$ coeffcients, and repeat with $\\beta_1$ , and $\\alpha_1+\\beta_1$.   Comment on the cross-sectional variation of the $\\alpha_1,\\beta_1$,  and $\\alpha_1+\\beta_1$ and on the consequences that the values of these coeffcients have on the behaviour of the estimated volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f30b36",
   "metadata": {},
   "source": [
    "* Plot the histogram of the 100 $\\alpha_1$ coeffcients, and repeat with $\\beta_1$ , and $\\alpha_1+\\beta_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66319686",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "par(bg = \"#f7f7f7\")\n",
    "par(mfrow = c(3, 1))\n",
    "\n",
    "hist(stock_coef[,\"alpha1\"], n = 100, probability = TRUE, border = \"white\",\n",
    "     col = \"steelblue\",xlab = NA, main = \"Alpha1\" )\n",
    "\n",
    "hist(stock_coef[,\"beta1\"], n = 100, probability = TRUE, border = \"white\",\n",
    "     col = \"steelblue\", xlab = NA, main = \"Beta1\" )\n",
    "\n",
    "hist(stock_coef[,\"alpha1+beta1\"], n = 100, probability = TRUE, border = \"white\",\n",
    "     col = \"steelblue\", xlab = NA, main = \"Alpha1+Beta1\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca10e40",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "In a GARCH(1,1) process, we have formula as**  \n",
    "$$ y_t = \\mu_t + a_t  $$\n",
    "**$a_t$ is for volatility, $\\mu_t$ is mean.**\n",
    "\n",
    "$$ a_t = \\sigma_t \\epsilon_t \\\\\n",
    "\\sigma_t^2 = \\omega + \\alpha_1 a_{t - 1}^2 + \\beta_1 \\sigma_{t - 1}^2.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad7590",
   "metadata": {},
   "source": [
    "**We notice that in GRACH(1,1) model, all stocks $\\alpha_1+\\beta_1$ are close to 1.  \n",
    "When $\\beta_1$ is small, the volatility cluster is not obvious. But when $\\beta_1$ is greater, because the autocorrelation of $\\sigma$ is higher, the volatility spike persistence will longer, there will be a slow decay of volatility, and will show volatility clustering.   \n",
    "So from the formula we could see, the volatility equation combines connection with past returns as well as autoregressive dependence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561df26",
   "metadata": {},
   "source": [
    "###  4. Find the minimum and maximum values of $\\alpha_1,\\beta_1$,  and $\\alpha_1+\\beta_1$.  Comment briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70441ae",
   "metadata": {},
   "source": [
    "* Show the minimum and maximum parameters of the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5344e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply(stock_coef, 2, range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e2fe2",
   "metadata": {},
   "source": [
    "* Locate the Stocks with maximum and minimum parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(stock_coef[,\"alpha1\"])\n",
    "which.max(stock_coef[,\"alpha1\"])\n",
    "min(stock_coef[,\"beta1\"])\n",
    "which.min(stock_coef[,\"beta1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554dba3",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>Stock1 GNW</span> has <span style='background:yellow'>Maximum $\\alpha_1$</span> at 0.56, as well as minimum $\\beta_1$ at 0.42.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9289597",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(stock_coef[,\"beta1\"])\n",
    "which.max(stock_coef[,\"beta1\"])\n",
    "min(stock_coef[,\"alpha1\"])\n",
    "which.min(stock_coef[,\"alpha1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95a604",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>Stock2 CHRW</span> has Minimum $\\alpha_1$ at 0.004, as well as <span style='background:yellow'>Maximum $\\beta_1$</span> at 0.98.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4924dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(stock_coef[,\"alpha1+beta1\"])\n",
    "which.min(stock_coef[,\"alpha1+beta1\"])\n",
    "max(stock_coef[,\"alpha1+beta1\"])\n",
    "which.max(stock_coef[,\"alpha1+beta1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6a82f",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>Stock3 PRGO</span>  has <span style='background:yellow'>Minimum $\\alpha_1+\\beta_1$</span> at 0.73, while <span style='background:yellow'>Stock4 PSX</span>  has <span style='background:yellow'>Maximum $\\alpha_1+\\beta_1$</span> at 0.99.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73365036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check the highest Volatility stock\n",
    "max(stock_coef[,\"omega\"])\n",
    "which.max(stock_coef[,\"omega\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177c133",
   "metadata": {},
   "source": [
    "**<span style='background:yellow'>Stock5 BBBY</span>  has <span style='background:yellow'>Highest Volatility $\\omega$</span> at 7.05.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0edc4",
   "metadata": {},
   "source": [
    "* Plot those stocks with extreme parameters for comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1042110",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "par(mfrow = c(3, 2))\n",
    "\n",
    "plot(lrets$GNW,  main = \"GNW.Max Alpha1\")\n",
    "plot(lrets$CHRW,  main = \"CHRW.Max Beta1\")\n",
    "plot(lrets$PRGO,  main = \"PRGO.Min Alpha1+Beta1\")\n",
    "plot(lrets$PSX,  main = \"PSX.Max Alpha1+Beta1\")\n",
    "plot(lrets$BBBY,  main = \"BBBY.Max omega\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6192213",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From the chart, Stock4 PSX which has <span style='background:yellow'>Maximum $\\alpha_1+\\beta_1$</span> shows volatility spike persistence much longer, as well as much slower decay after spikes, and also shows the existing of volatility clustering.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f059ab9",
   "metadata": {},
   "source": [
    "* Plot the volatility chart for stocks with Maximum and minimum $\\alpha_1+\\beta_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f80c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lrets <- merge(lrets$PRGO, lrets$PSX, all=TRUE)\n",
    "autoplot(t_lrets, facets = FALSE) + geom_line() + theme_wsj()+ \n",
    "    scale_colour_wsj(\"dem_rep\")+ ggtitle(\"Volatility Clustering Effects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6061eb",
   "metadata": {},
   "source": [
    "**<span style='background: lightblue'>Conclutions:</span>  \n",
    "By comparing the volatility of <span style='color:red'>Stock PXS with Maximum $\\alpha_1+\\beta_1$</span> to <span style='color:blue'>Stock PRGO with Minimum $\\alpha_1+\\beta_1$</span>, we could clearly see PXS shows more volatility clustering Effects than PRGO.   \n",
    "Although both stocks have zero-means, returns in blue line, tends to back to mean much faster then red line. The returns in red line obviously are not independent, after a large return change, another large change tends to follow in the next day. This pattern in the volatility clusters, shows the past shocks are persistent, negative shocks even persisted longer.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62ad7d",
   "metadata": {},
   "source": [
    "### 5. Use the GARCH volatility of the cross-section of 100 stocks for every day to obtain median \"market\" volatility and its quantiles (95% and 5%). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd47e5a",
   "metadata": {},
   "source": [
    "* Observe stock volatility by chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672176d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(bg = \"#f7f7f7\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "plot(stock_coef[,\"omega\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be1d83b",
   "metadata": {},
   "source": [
    "* Apply GARCH result to calculate cross-section \"market\" volatility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f60e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_vol <- median(stock_coef[,\"omega\"])\n",
    "median_vol\n",
    "quantile(stock_coef[,\"omega\"],c(0.05, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808705a",
   "metadata": {},
   "source": [
    "**Coments:  \n",
    "Our median \"market\" volatility is 0.207, 5% quantiles at 0.058, 95% quantiles at 1.456.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ceea9",
   "metadata": {},
   "source": [
    "### Create a figure plotting the cross-section of median, the 95% quantile, and the 5% quantile \"market\" volatility that you have obtained. Please, comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(bg = \"#f7f7f7\")\n",
    "options(repr.plot.width = 10, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 2))\n",
    "plot((1:N - 1)/(N - 1), sort(stock_coef[,\"omega\"]), type=\"l\",\n",
    "     main = \"Cross-section Volatility Quantiles\", xlab = \"Fraction\", ylab = \"Quantile\")\n",
    "\n",
    "hist(stock_coef[,\"omega\"], n = 100, probability = TRUE, border = \"white\",\n",
    "     col = \"steelblue\", xlab = NA, main = \"Cross-section Market Volatility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252eded7",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "By formula defination $$\\sigma_t^2 = \\omega + \\alpha_1 a_{t - 1}^2 + \\beta_1 \\sigma_{t - 1}^2$$ \n",
    "we could see $\\omega$ is the long-term volatility. From our observation of Cross-section volatility from GARCH model results, 95% of stocks has $\\omega$ lower than 1.5.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d986886",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8328ce",
   "metadata": {},
   "source": [
    "### Use the dataset of logarithmic returns from the first problem. Compute the mean logarithmic return for each date. Estimate a suitable ARMA family model for this series. Consider at least three different ARMA orders that you can pinpoint as candidate models by observing the ACF and PACF. Remember to include all the necessary steps including model diagnostics. Discuss the results in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3cb56",
   "metadata": {},
   "source": [
    "### 1.  Compute the mean logarithmic return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"2-Returns.RData\")\n",
    "\n",
    "length(lrets)\n",
    "names(lrets)\n",
    "head(lrets[[1]])\n",
    "tail(lrets[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be2c4a",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "We need to manipulate the list in the way that all symbols have matching timestamps, so it is necessary to check if all time-serie observations are matching each other.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458daaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check time stamps\n",
    "p_dates <- index(lrets[[1]])\n",
    "length(p_dates)\n",
    "for (i in 2:length(lrets)){\n",
    "    p_dates <- index(lrets[[i]])[index(lrets[[i]]) %in% p_dates]\n",
    "}\n",
    "length(p_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec7629",
   "metadata": {},
   "source": [
    "* Calculate mean logarithmic return for each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time serises of cross sector means\n",
    "N <- nrow(lrets[[1]])  \n",
    "lrets_mean <- sapply(1:N, function(y){\n",
    "   mean(sapply(lrets, '[[', y)) \n",
    "})\n",
    "\n",
    "length(lrets_mean)\n",
    "head(lrets_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an xts object\n",
    "lrets_xts <- xts(lrets_mean, index(lrets[[1]]))\n",
    "head(lrets_xts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9ecd9",
   "metadata": {},
   "source": [
    "### 2. Estimate a suitable ARMA family model for this series. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54546777",
   "metadata": {},
   "source": [
    "* (1). We start with plotting the time series shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb49a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "plot(lrets_xts,  xlab = 'Year', ylab = 'Percent', main = 'Mean Logarithmic Return', \n",
    "     axes = F, cex.main = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d5a4ad",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From the plot we could feel that the Mean is probably 0, there is clearly autocorrelations, and it should be stationary. And from the chart we could not see obvious jump or shift, so no need for subsample testing.   \n",
    "Also we could observe when Covid started at 2020 spring, there is a spike of much higher volatility and the chart shows volatility clustering after. Also at Winter of 2020 when Delta Covid appeared, there was high volatility and persisit cluster.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80690e8",
   "metadata": {},
   "source": [
    "* (2). Apply lag depenency test by exploring ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bfa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "par(bg = \"#f7f7f7\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 2))\n",
    "acf(lrets_xts, main = NA, lag = 50)\n",
    "pacf(lrets_xts, main = NA, lag = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794c332",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From ACF and PACF test, there seems a lot of dependence visible in first 8 lags, especially at lag 1 and 2, so <span style='background:yellow'>we choose AR(1), ARMA(1,1) and ARMA(2,1)</span> as candidate models.  \n",
    "And we could not rule out stationarity based on ACF and PACF, still need to conduct a formal test for autocorrelation and stationarity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662a3c6",
   "metadata": {},
   "source": [
    "*  (3). Apply Ljun-Box test to check if this time series contains autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe92ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box.test(lrets_xts, type = 'Ljung-Box')\n",
    "Box.test(lrets_xts, lag = 8, type = 'Ljung-Box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283817f3",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "As we expected, since both Box-Ljung test for 1 lag and 8 lags have p_value < 0.01, so <span style='background:yellow'>this time series has autocorrelation</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bbd89c",
   "metadata": {},
   "source": [
    "* (4). Formal test for stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.test(lrets_xts, k = 1)\n",
    "adf.test(lrets_xts, k = 5)\n",
    "adf.test(lrets_xts, k = 10)\n",
    "\n",
    "kpss.test(lrets_xts, null = 'Level')\n",
    "kpss.test(lrets_xts, null = 'Trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76b7ba",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "Because in Augmented Dickey-Fuller Test all testing p-value results < 0.05, and in KPSS Test all testing p-value results > 0.05, so we could reject non-stationarity, and conclude that <span style='background:yellow'>this time series is stationary</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7cefc1",
   "metadata": {},
   "source": [
    "* (5). Apply Auto Arima Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrets_auto <- auto.arima(lrets_xts, max.d = 0)\n",
    "lrets_auto\n",
    "\n",
    "par(bg = \"#f7f7f7\")\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 2))\n",
    "\n",
    "acf(lrets_auto$residuals, main = NA)\n",
    "pacf(lrets_auto$residuals, main = NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f6613",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From ACF and PACF Test of residuals, We could see depenency at lag 1, 7, and 17.  \n",
    "And auto.arima suggest ARMA(4,4).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89882a8d",
   "metadata": {},
   "source": [
    "### 3. Consider at least three different ARMA orders that you can pinpoint as candidate models by observing the ACF and PACF. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0c9db",
   "metadata": {},
   "source": [
    "* (1). First we try AR(1) as starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517550f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Arima package to feed AR(1), (AR order, diff, MA roder)\n",
    "lrets_ar1 <- Arima(lrets_xts, order = c(1, 0, 0))\n",
    "summary(lrets_ar1)\n",
    "\n",
    "plot(lrets_ar1$residuals, type = 'h', ylab = NA, main = 'Residuals')\n",
    "\n",
    "par(mfrow = c(1, 2))\n",
    "acf(lrets_ar1$residuals, main = 'Residuals - ACF')\n",
    "pacf(lrets_ar1$residuals, main = 'Residuals - PACF')\n",
    "acf(lrets_ar1$residuals ^ 2, main = 'Squared residuals - ACF')\n",
    "pacf(lrets_ar1$residuals ^ 2, main = 'Squared residuals - PACF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccd647",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "Just see the coefficient at -0.17 and a huge standard error sigma^2 at 2.4, we would know  <span style='background:yellow'>AR(1) would not be the answer</span>.  Also there is many autocorrelation in residuals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1636c",
   "metadata": {},
   "source": [
    "* (2). Next, try if ARMA(1, 1) would be a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ARMA(1,1), order is 1,0,1  (AR, Diff, MA)\n",
    "lrets_arma11 <- Arima(lrets_xts, order = c(1, 0, 1))\n",
    "summary(lrets_arma11)\n",
    "plot(lrets_arma11$residuals, type = 'h', ylab = NA, main = 'Residuals')\n",
    "par(mfrow = c(1, 2))\n",
    "acf(lrets_arma11$residuals, main = 'Residuals - ACF')\n",
    "pacf(lrets_arma11$residuals, main = 'Residuals - PACF')\n",
    "acf(lrets_arma11$residuals ^ 2, main = 'Squared residuals - ACF')\n",
    "pacf(lrets_arma11$residuals ^ 2, main = 'Squared residuals - PACF')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da3315",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "Coefficient incresed to -0.52, but still huge standard error sigma^2 at 2.41, as well as many autocorrelation in residuals, so  <span style='background:yellow'>ARMA(1,1) clearly is not the good fit either</span>.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box.test(lrets_arma11$residuals, type = \"Ljung-Box\", lag = 4)\n",
    "Box.test(lrets_arma11$residuals, type = \"Ljung-Box\", lag = 8)\n",
    "Box.test(lrets_arma11$residuals, type = \"Ljung-Box\", lag = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ce6c2",
   "metadata": {},
   "source": [
    "**Just as we expected, Box-Ljung test for lag 8 and 12 have p_value < 0.01, the residuals have many autocorrelations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd501e3",
   "metadata": {},
   "source": [
    "* (3). Try ARMA(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4220b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ARMA(2,1), order is 2,0,1  (AR, Diff, MA)\n",
    "lrets_arma21 <- Arima(lrets_xts, order = c(2, 0, 1))\n",
    "summary(lrets_arma21)\n",
    "plot(lrets_arma21$residuals, type = 'h', ylab = NA, main = 'Residuals')\n",
    "par(mfrow = c(1, 2))\n",
    "acf(lrets_arma21$residuals, main = 'Residuals - ACF')\n",
    "pacf(lrets_arma21$residuals, main = 'Residuals - PACF')\n",
    "acf(lrets_arma21$residuals ^ 2, main = 'Squared residuals - ACF')\n",
    "pacf(lrets_arma21$residuals ^ 2, main = 'Squared residuals - PACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56f399",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "In ARMA(2,1) there are still some autocorrelation in residuals, so we do the LB test for residual dependency.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box.test(lrets_arma21$residuals, type = \"Ljung-Box\")\n",
    "Box.test(lrets_arma21$residuals, type = \"Ljung-Box\", lag = 3)\n",
    "Box.test(lrets_arma21$residuals, type = \"Ljung-Box\", lag = 6)\n",
    "Box.test(lrets_arma21$residuals, type = \"Ljung-Box\", lag = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71df6e8",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From Box-Ljung test, seems lags 6 and 8 have p_value < 0.01, so there still are dependency in residuals. <span style='background:yellow'>ARMA(2,1) is still not the right answer</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc2dc4",
   "metadata": {},
   "source": [
    "* (4). Test ARIMA's suggestion of ARMA(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f54ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ARMA(4,4), order is 4,0,4  (AR, Diff, MA)\n",
    "lrets_arma44 <- Arima(lrets_xts, order = c(4, 0, 4))\n",
    "summary(lrets_arma44)\n",
    "plot(lrets_arma44$residuals, type = 'h', ylab = NA, main = 'Residuals')\n",
    "par(mfrow = c(1, 2))\n",
    "acf(lrets_arma44$residuals, main = 'Residuals - ACF')\n",
    "pacf(lrets_arma44$residuals, main = 'Residuals - PACF')\n",
    "acf(lrets_arma44$residuals ^ 2, main = 'Squared residuals - ACF')\n",
    "pacf(lrets_arma44$residuals ^ 2, main = 'Squared residuals - PACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3ce2c",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "In ARMA(4,4) looks better, but seems still has some distant autocorrelation in residuals, this could caused by the ARCH effect. so we do the residual auto-correlation test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef76ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Box.test(lrets_arma44$residuals, type = \"Ljung-Box\")\n",
    "Box.test(lrets_arma44$residuals, type = \"Ljung-Box\", lag = 7)\n",
    "Box.test(lrets_arma44$residuals, type = \"Ljung-Box\", lag = 10)\n",
    "Box.test(lrets_arma44$residuals, type = \"Ljung-Box\", lag = 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de06d00",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "From Box-Ljung test, for lag 1, 8, 10 and 17 all have p_value > 0.01, so seems the residual autocorrelation is removed. So <span style='background:yellow'>ARMA(4,4) could be the right answer</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c9b4c2",
   "metadata": {},
   "source": [
    "* Test for conditional heteroscedasticity in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123059ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrets_44 <- arima(lrets_xts, order = c(4, 0, 4))\n",
    "\n",
    "arch.test(lrets_44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abdf67",
   "metadata": {},
   "source": [
    "**Comments:  \n",
    "We do not see the conditional heteroscedasticity in the residuals results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4965be34",
   "metadata": {},
   "source": [
    "* (5). Compare models by Information Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models <- 4\n",
    "criteria <- matrix(ncol = 2, nrow = models)\n",
    "colnames(criteria) <- c('AIC', 'BIC')\n",
    "rownames(criteria) <- c('AR(1)', 'ARMA(1,1)', 'ARMA(2,1)', 'ARMA(4,4)')\n",
    "criteria[1, 1] <- lrets_ar1$aic\n",
    "criteria[1, 2] <- lrets_ar1$bic\n",
    "criteria[2, 1] <- lrets_arma11$aic\n",
    "criteria[2, 2] <- lrets_arma11$bic\n",
    "criteria[3, 1] <- lrets_arma21$aic\n",
    "criteria[3, 2] <- lrets_arma21$bic\n",
    "criteria[4, 1] <- lrets_arma44$aic\n",
    "criteria[4, 2] <- lrets_arma44$bic\n",
    "criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f91cd",
   "metadata": {},
   "source": [
    "**<span style='background: lightblue'>Conclutions:</span>  \n",
    "From Information Criteria, ARMA(4,4) has both lowest AIC and BIC, so <span style='background:yellow'>we select ARMA(4,4) as the best fit</span>.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
